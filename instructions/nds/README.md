NDS ResNet/ResNext
--------

We provide the supernet implementations of ResNet/ResNeXt-A search spaces in `my_nas/germ/germ_nds.py`.
* ResNet: `GermResNet`
* ResNeXt-A: `GermResNextA`


### Prepare

1. Install required packages by `pip install -r ./requirements.txt`, including the [`pycls` package](https://github.com/facebookresearch/pycls). (Note that `pycls` need Python>=3.7.6)
2. If you have the `pytest` tool/package installed, you can try run `pytest -x ./test_germ_nds.py` to run unit test for the ResNet/ResNeXt-A supernet. The tests should pass.
3. For derive and evaluation, one should use the data files under `nds_assets/`.
    * ResNet (25k archs): `resnet_archs_25k.yaml` contains a list of 25k arch genotypes; `resnet_gt_25k.pkl` contains all arch genotypes, param, flops, and test accs.
    * ResNet (3 seed runs, 5k archs): `resnet_archs_5k_3seed.yaml` contains a list of 5k arch genotypes; `resnet_gt_5k_3seed.pkl` contains the corresponding arch genotypes, param, flops, and test accs (average across 3 seed runs, see NDS paper Appendix A).
    * ResNeXt-A (25k archs): `resnexta_archs_25k.yaml` contains a list of 25k arch genotypes; `resnexta_gt_25k.pkl` contains all arch genotypes, param, flops, and test accs.
    
    The data files can be generated by 1) downloading the [original NDS data](https://github.com/facebookresearch/nds), 2) modifying the `NDS_DATA_HOME` variable in `dump_archyaml_andgtpkl.py` to the downloaded path, 3) run `python dump_archyaml_and_gtpkl.py` to generate.

    For architecture evaluation on ResNeXt-A, we randomly pick out 5k architectures for ranking quality evaluation in our paper, whose genotypes and information are in `resnexta_archs_5k.yaml` and `resnexta_gt_5k.pkl`.

### Train one-shot supernets
Run one-shot training on ResNet search space (using ordinal channel handler):
`mynas search resnet_ordinal_search.yaml --gpu 0 --train-dir ./results/nds_resnet/oneshot_supernet_training --seed 20 --save-every 100`

Run one-shot training on ResNeXt-A search space (using ordinal channel handler):
`mynas search resnexta_ordinal_search.yaml --gpu 0 --train-dir ./results/nds_resnext/oneshot_supernet_training --seed 20 --save-every 100`


### Eval architectures using one-shot supernets

Run `eval-arch` for 5k archs in the ResNet search space:
```
mynas eval-arch resnet_ordinal_search.yaml resnet_archs_5k_3seed.yaml --load [check point dir (named by the epoch number)] --dump-rollouts [eval results pickle file] --gpu 0 --seed 123
```

Run `eval-arch` for 5k archs in the ResNeXt-A search space:
```
mynas eval-arch resnexta_ordinal_search.yaml resnexta_archs_5k.yaml --load [check point dir (named by the epoch number)] --dump-rollouts [eval results pickle file] --gpu 0 --seed 123
```

To run multiple `eval-arch` processes using multiple different checkpoints in a batched manner (on multiple GPUs), check `examples/research/surgery/run_derive_ckpts.py`.
